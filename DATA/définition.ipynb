{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def etude_fichier(df):\n",
    "\n",
    "    print(\"Nombre de colonnes :\", df.shape[1])\n",
    "    print()\n",
    "    print(\"Le type est : \\n\", df.dtypes)\n",
    "    print()\n",
    "    print('Nombre de valeurs uniques :')\n",
    "    print(df.nunique())\n",
    "    print()\n",
    "    print('Le nombre de valeurs manquantes :\\n', df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_statistique(df):\n",
    "\n",
    "    stats = df.describe(include='all')\n",
    "    stats.loc['median'] = df.median()\n",
    "    stats.loc['range'] = df.max() - df.min()\n",
    "    stats.loc['skewness'] = df.skew()\n",
    "    stats.loc['kurtosis'] = df.kurtosis()\n",
    "\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def detecter_outliers(df, column, seuil=2.0):\n",
    "    \"\"\"\n",
    "    Détecte les outliers dans une colonne d'un DataFrame en utilisant le Z-score.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): Le DataFrame contenant les données numériques.\n",
    "        column (str): Le nom de la colonne à étudier.\n",
    "        seuil (float): Le seuil pour définir les outliers. Par défaut, 2.0.\n",
    "\n",
    "    Returns:\n",
    "        float: Le pourcentage d'outliers dans la colonne spécifiée.\n",
    "    \"\"\"\n",
    "    if column not in df.columns:\n",
    "        raise ValueError(f\"La colonne '{column}' n'existe pas dans le DataFrame.\")\n",
    "    \n",
    "    series = df[column]\n",
    "    z_scores = np.abs((series - series.mean()) / series.std())\n",
    "    outliers_mask = z_scores > seuil\n",
    "    outliers_percentage = (outliers_mask.mean() * 100).round(2)\n",
    "    return outliers_percentage\n",
    "\n",
    "# Exemple d'utilisation :\n",
    "# Supposons que vous ayez un DataFrame df avec des colonnes numériques\n",
    "# Vous pouvez détecter le pourcentage d'outliers pour la colonne 'colonne1' comme suit :\n",
    "pourcentage_outliers_colonne1 = detecter_outliers(df, column='colonne_1', seuil=2.0)\n",
    "print(pourcentage_outliers_colonne1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_cles(df):\n",
    "    \"\"\"\n",
    "    Analyse les colonnes du DataFrame pour détecter les clés primaires et les clés étrangères potentielles.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): Le DataFrame à analyser.\n",
    "\n",
    "    Returns:\n",
    "        dict: Un dictionnaire contenant deux listes, l'une pour les clés primaires et l'autre pour les clés étrangères potentielles.\n",
    "    \"\"\"\n",
    "    primary_keys = []\n",
    "    foreign_keys = []\n",
    "\n",
    "    for column in df.columns:\n",
    "        unique_count = df[column].nunique()\n",
    "        total_count = df[column].count()\n",
    "\n",
    "        if unique_count == total_count:\n",
    "            primary_keys.append(column)\n",
    "        elif unique_count > 1 and unique_count < total_count:\n",
    "            foreign_keys.append(column)\n",
    "\n",
    "    return {\"primary_keys\": primary_keys, \"foreign_keys\": foreign_keys}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identifier_differences_entre_cles(df1, df2, keys=None):\n",
    "    \"\"\"\n",
    "    Identifie les différences entre les clés (clés primaires ou colonnes spécifiées) de deux DataFrames.\n",
    "\n",
    "    Args:\n",
    "        df1 (pandas.DataFrame): Le premier DataFrame.\n",
    "        df2 (pandas.DataFrame): Le deuxième DataFrame.\n",
    "        keys (list or str, optional): Les clés (nom des colonnes) à utiliser pour l'identification des différences. \n",
    "                                     Si None, utilise les clés primaires (colonnes ayant le même nom dans les deux DataFrames).\n",
    "                                     Par défaut, None.\n",
    "\n",
    "    Returns:\n",
    "        dict: Un dictionnaire contenant deux listes, l'une pour les clés présentes uniquement dans df1,\n",
    "              et l'autre pour les clés présentes uniquement dans df2.\n",
    "    \"\"\"\n",
    "    if keys is None:\n",
    "        keys = list(df1.columns.intersection(df2.columns))\n",
    "\n",
    "    unique_keys_df1 = set(df1[keys].drop_duplicates().apply(tuple, axis=1))\n",
    "    unique_keys_df2 = set(df2[keys].drop_duplicates().apply(tuple, axis=1))\n",
    "\n",
    "    keys_only_in_df1 = unique_keys_df1 - unique_keys_df2\n",
    "    keys_only_in_df2 = unique_keys_df2 - unique_keys_df1\n",
    "\n",
    "    return {\"keys_only_in_df1\": list(keys_only_in_df1), \"keys_only_in_df2\": list(keys_only_in_df2)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traiter_valeurs_manquantes(df, method='mean', columns=None):\n",
    "    \"\"\"\n",
    "    Remplace les valeurs manquantes du DataFrame en utilisant différentes méthodes.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): Le DataFrame à traiter.\n",
    "        method (str): La méthode de remplacement des valeurs manquantes. \n",
    "                      'mean' pour la moyenne, 'median' pour la médiane, 'mode' pour le mode, etc.\n",
    "        columns (list or str, optional): La (ou les) colonne(s) spécifique(s) sur laquelle (lesquelles) appliquer le traitement.\n",
    "                                         Si None, applique le traitement à toutes les colonnes. Par défaut, None.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: Le DataFrame avec les valeurs manquantes traitées.\n",
    "    \"\"\"\n",
    "    if method == 'mean':\n",
    "        if columns is None:\n",
    "            return df.fillna(df.mean())\n",
    "        else:\n",
    "            return df.fillna(df.mean()[columns])\n",
    "    elif method == 'median':\n",
    "        if columns is None:\n",
    "            return df.fillna(df.median())\n",
    "        else:\n",
    "            return df.fillna(df.median()[columns])\n",
    "    elif method == 'mode':\n",
    "        if columns is None:\n",
    "            return df.fillna(df.mode().iloc[0])\n",
    "        else:\n",
    "            return df.fillna(df.mode().iloc[0][columns])\n",
    "    else:\n",
    "        return df.fillna(method=method)\n",
    "\n",
    "# Exemple d'utilisation :\n",
    "# Supposons que vous ayez un DataFrame df avec une colonne 'colonne1' que vous voulez traiter les valeurs manquantes avec la moyenne :\n",
    "# df_traite = traiter_valeurs_manquantes(df, method='mean', columns='colonne1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_variables_categorielles(df, columns_to_encode):\n",
    "    \"\"\"\n",
    "    Encode les variables catégorielles du DataFrame en utilisant la technique de \"one-hot encoding\".\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): Le DataFrame contenant les variables catégorielles à encoder.\n",
    "        columns_to_encode (list): Liste des noms de colonnes catégorielles à encoder.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: Le DataFrame avec les variables catégorielles encodées.\n",
    "    \"\"\"\n",
    "    return pd.get_dummies(df, columns=columns_to_encode)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def regression_lineaire(X, y):\n",
    "    \"\"\"\n",
    "    Effectue une régression linéaire simple.\n",
    "\n",
    "    Args:\n",
    "        X (numpy.ndarray): Les caractéristiques (variables indépendantes).\n",
    "        y (numpy.ndarray): La variable cible (variable dépendante).\n",
    "\n",
    "    Returns:\n",
    "        sklearn.linear_model.LinearRegression: Le modèle de régression linéaire entraîné.\n",
    "    \"\"\"\n",
    "    model = LinearRegression()\n",
    "    model.fit(X, y)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def separation_entrainement_test(X, y, test_size=0.2, random_state=None):\n",
    "    \"\"\"\n",
    "    Sépare les données en ensembles d'entraînement et de test.\n",
    "\n",
    "    Args:\n",
    "        X (numpy.ndarray): Les caractéristiques (variables indépendantes).\n",
    "        y (numpy.ndarray): La variable cible (variable dépendante).\n",
    "        test_size (float, optional): La proportion des données à inclure dans l'ensemble de test. Par défaut, 0.2.\n",
    "        random_state (int, optional): La graine aléatoire pour la reproductibilité. Par défaut, None.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Un tuple contenant les ensembles d'entraînement et de test pour X et y.\n",
    "    \"\"\"\n",
    "    return train_test_split(X, y, test_size=test_size, random_state=random_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def etudier_jointures(df1, df2, on_column):\n",
    "    \"\"\"\n",
    "    Effectue une étude des jointures possibles entre deux DataFrames en utilisant la colonne spécifiée comme clé de jointure.\n",
    "\n",
    "    Args:\n",
    "        df1 (pandas.DataFrame): Le premier DataFrame.\n",
    "        df2 (pandas.DataFrame): Le deuxième DataFrame.\n",
    "        on_column (str): Le nom de la colonne à utiliser comme clé de jointure.\n",
    "\n",
    "    Returns:\n",
    "        dict: Un dictionnaire contenant les résultats de chaque jointure (inner, left, right, outer) \n",
    "              et une analyse des clés résultantes.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "\n",
    "    # Jointure interne (inner join)\n",
    "    results['inner_join'] = pd.merge(df1, df2, how='inner', on=on_column)\n",
    "    results['inner_join_analysis'] = analyse_cles_jointure(results['inner_join'], on_column)\n",
    "\n",
    "    # Jointure à gauche (left join)\n",
    "    results['left_join'] = pd.merge(df1, df2, how='left', on=on_column)\n",
    "    results['left_join_analysis'] = analyse_cles_jointure(results['left_join'], on_column)\n",
    "\n",
    "    # Jointure à droite (right join)\n",
    "    results['right_join'] = pd.merge(df1, df2, how='right', on=on_column)\n",
    "    results['right_join_analysis'] = analyse_cles_jointure(results['right_join'], on_column)\n",
    "\n",
    "    # Jointure externe complète (full outer join)\n",
    "    results['outer_join'] = pd.merge(df1, df2, how='outer', on=on_column)\n",
    "    results['outer_join_analysis'] = analyse_cles_jointure(results['outer_join'], on_column)\n",
    "\n",
    "    return results\n",
    "\n",
    "def analyse_cles_jointure(df, on_column):\n",
    "    \"\"\"\n",
    "    Analyse les clés résultantes d'une jointure.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): Le DataFrame résultant de la jointure.\n",
    "        on_column (str): Le nom de la colonne utilisée comme clé de jointure.\n",
    "\n",
    "    Returns:\n",
    "        dict: Un dictionnaire contenant le nombre de clés uniques avant et après la jointure.\n",
    "    \"\"\"\n",
    "    unique_keys_before = df[on_column].nunique()\n",
    "    unique_keys_after = df.drop_duplicates(subset=on_column)[on_column].nunique()\n",
    "\n",
    "    return {\"unique_keys_before\": unique_keys_before, \"unique_keys_after\": unique_keys_after}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
